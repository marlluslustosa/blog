---
title: Dynamic highlighting of posts on a static website - with email and telegram notifications
author: marllus
categories:
- technology
layout: post
image: assets/images/teia.jpg
image-ref: Photo by <a href="https://unsplash.com/@joshcala">Josh Calabrese</a>
tags:
- goatcounter
- jekyll
- javascript
- github actions
- popularity
- featured posts
id-ref: destaque-dinamico
---

By [definition](https://en.wikipedia.org/wiki/Static_web_page), a static site, or a page that has been generated by static site generators - SSG, is one whose content cannot be easily changed on the side server, ie not dynamic enough to support *server side* changes. Is it really that? Well, that's what we'll see. :)

#### The restlessness

There is one big advantage and another disadvantage on the same level between the world of static websites. The first is that the final generated content becomes very fast to load (I got the record of [0.8 seconds](https://www.webpagetest.org/result/210531_AiDcA2_db665fc676bb41970c884837e3492bd8/) in my site's load time), however, the downside of this is the difficulty in working well with dynamic content, which needs to be changed on the server side, that is, a change that is effective for all users who access it. Based on this, many people prefer to adopt tools, such as Wordpress, that make this deployment process less dramatic and painful. But my goal was not to play the cards on the table.

Thinking about it, came a uneasiness. On my blog, made with [Jekyll](https://jekyllrb.com/), there is an option to put a number of stars on the articles (ranging from 1 to 5), and on the home page there is a the highlights section , or the most read articles. For example, whenever I write a post, on the `.md` page, there are two parameters to be defined, called `featured` and `rating`, which serve to specify that the article is a highlight and how many stars it will have, respectively. I can define it however I want. Of course, on a static site, this information becomes fictitious, as by default it's up to me to specify, that is, it's not automatic, based on user ratings or how much that article was actually viewed by the public. A purely manual process.

So, I wondered if I didn't have an option to make this more dynamic. In short, I wanted to use the information about the access count to posts, which I use via [GoatCounter](https://www.goatcounter.com/) (great service, by the way), and in a period of time a script would be executed , on some server, on the crazy web out there, to analyze the most read, in order to do this himself, that is, change the highlighted articles automatically and notify me of such change. Phew... a little work, thought. But while I was mentally looking for a place where this script could be run, without having to rent a full VM, a light came to me... Oops... What if I used [Github Actions](https://docs.github.com/en/actions/learn-github-actions) itself for this? Hmm... Things were starting to unfold, as I could do the entire procedure where I host my blog: on github.

For those who don't know, github provides a kind of tool that executes scripts in the users' repository, simulating an [operating system](https://github.com/actions/virtual-environments). The idea is to perform automated integration, delivery and deployment tests, based on any events that happen in the repository itself (hence the [CI/CD pipelines](https://www.redhat.com/pt-br/ topics/devops/what-is-ci-cd) - one of the foundations for the DevOps workflow). And look, one of these events can be fired in a [scheduled](https://docs.github.com/pt/actions/reference/events-that-trigger-workflows#) way (in `cron` format). In short, it is a "cheap" infrastructure because this environment is shared and not dedicated 24 hours a day for such action. Check the [usage limits](https://docs.github.com/en/actions/reference/usage-limits-billing-and-administration). Another option is [Gitlab CI](https://docs.gitlab.com/ee/ci/), which also does the same thing and has generous limits on the free option.

So, not knowing if it would really work, I set up the following development schedule:

- Capturar e tratar informações sobre o número de visitas ao site;

- Criar um script para gerar um arquivo com os artigos mais vistos;

- Criar um script para retirar os artigos antigos da tela de destaques e adicionar os novos mais vistos (4 últimos);

- Criar uma forma de atualizar os arquivos da página no github com as novas informações, sem precisar ter que atualizar manualmente;

- Por fim, ser notificado das mudanças;

Parece meio cheio, né? Mas, felizmente, a saga, que durou pouco mais de dois restos de dias, resolveu todas as questões para execução do fluxo. Apesar de a solução ter ficado bastante personalizada para a minha necessidade, esse artigo, com um leve tom fantástico, tem por objetivo mostrar que é possível fazer esse tipo de alteração no lado do servidor, mesmo em sites estáticos, dotando-o, portanto, de mais autonomia para se modificar dinamicamente.

#### Tratando as informações sobre os acessos - GoatCounter

No [site](https://www.goatcounter.com/code/api) do GoatCounter existe uma boa documentação sobre como usar a sua API para processar os dados sobre visitas ao site. Adaptei um script que já estava lá para puxar esses dados e assim ficou:

<script src="https://gist.github.com/marlluslustosa/d2df55799c05cb838fbd3a79bc4a2401.js"></script>

Basicamente o script bash acima acessa a API do goatcounter e imprime na tela o arquivo referente a todos os acessos ao blog. Agora, com os dados brutos, iniciei o processo de tratamento, afim de tonar a visualização fácil, em outras palavras, ter um arquivo com os 4 artigos mais vistos e a quantidade de visitas de cada um.

<script src="https://gist.github.com/marlluslustosa/84d615ad0e702f1085a5262b69016431.js"></script>

Agora perceba que esse script trabalha com o arquivo `export.txt`, que é o conteúdo da saída do script anterior `export_goat.sh`, ou seja, os dados brutos de acesso. Aqui eu usei o `sed`, meu editor preferido para tramento de grandes volumes de dados. Através do uso de expressões regulares para limpá-lo, o script gerou dois arquivos: `ranking_posts` e `ranking_posts_name`. O primeiro, que contém, linha por linha, os nomes dos últimos 4 artigos, foi usado no loop (linha 16) para percorrê-los e adicionar os parâmetros `featured=true` (artigo em destaque) e estrelas (`rating`), em ordem decrescente. Como o GoatCounter funciona basicamente como uma catraca (contando acessos e nada mais), utilizei a lógica de 5 estrelas para o primeiro artigo mais lido, 4 para o segundo, 3 para o terceiro e 2 para o quarto. Isso tem por objetivo saber, logo na visualização da primeira página, qual a ordem dos destaques mais vistos, com base nas estrelas. Perceba que antes dessa alteração, na linha 9,  ele percorre todos os artigos do site (`*.md`) e remove qualquer menção anterior ao `featured` ou `rating`, afim de não gerar artigos com essas informações duplicadas. Poderia ter colocado tudo no mesmo loop? Sim, poderia. Esse é o lado bom de programar: múltiplas formas.

E quanto ao arquivo `ranking_posts_name`? Ele contém o texto já tratado que servirá no disparo das notificações. Então, pensando nisso, pensei em brincar com mensageria, além do e-mail ([sendgrid](https://sendgrid.com/)), que já usei [aqui](https://marllus.com/tecnologia/2020/10/14/pipeline-watchtower.html). Na versão [gratuita](https://sendgrid.com/pricing/) do sendgrid, você tem um limite de envio de 100 emails por dia, o que dará para esse trabalho. Para quem não tem experiência em criação de bots no telegram, pode conferir a documentação [aqui](https://core.telegram.org/bots).

#### O fluxo completo - goatcounter, commit/push, sendgrid e telegram

Depois de ter explicado as partes menores, agora vou detalhar o resultado do todo, que une essas partes e as integra em uma lógica de execução. É aí que entra o papel do Github Actions, que vai executar as partes. Aqui está meu workflow:

<script src="https://gist.github.com/marlluslustosa/0f77d3d9927604141d1c299efdf25b87.js"></script>

Linha 4 e linha 7 representam o momento em que este workflow será executado, ou seja, em todo `push` para `branch master` (em outras palavras, todas as vezes que você fizer alterações no site) e todos os dias às 7h da manhã. Detalhes de sintaxe à parte, aqui você precisa saber que `steps` indica as etapas do processo de trabalho definido (`job build`). Então, na lógica sequencial, o primeiro `step` (`Create local changes`) vai executar o script `export_goat.sh`. As variáveis `secrets.TOKEN_GOAT` e `secrets.API_URL_GOAT`, como o próprio nome já diz, são variáveis do tipo secretas, necessárias para autenticar na conta GoatCounter configurada no blog, para obter os dados de acesso. Eu as defini assim como secrets para não ficarem expostas, já que tanto o script como o workflow completo é aberto ao público. Uma das vantagens [desse recurso](https://docs.github.com/pt/actions/reference/encrypted-secrets) do github é você poder criptografar qualquer string ou valor que deseja esconder, incluindo senhas e tokens de acesso. Durante a execução do fluxo, somente o ambiente executor virtual privado é que terá acesso ao conteúdo dessas variáveis, portanto, longe de olhos atentos.

A lógica que eu desenvolvi para o processo global foi: 

- 1 - Execute o script para para obter os dados de acesso e escreva no arquivo `export.txt`; 

- 2 - Antes de gerar um novo arquivo `ranking_posts`, faça uma cópia dele, nomeando-do `ranking_posts_old`, e após isso compare os dois. Caso sejam iguais, então não houve alteração na ordem dos mais vistos, portanto mantenha o log de ranking atual, caso contrário, registre isso em uma variável (`NEWFILERANKING=true`) para ser lida nos passos de notificação;

- 3 - Altere o repositório (commit/push) de acordo com as mudanças - caso algum arquivo seja alterado -, em outras palavras, somente se no passo anterior ele encontrar alterações no ranking dos mais vistos;

- 4 - Caso o arquivo referente ao ranking tenha sido alterado (ou seja, se variável `NEWFILERANKING` registrar isso no passo 2), então envie um e-mail e notifique via telegram sobre as mudanças;

Basicamente são esses passos, que traduzindo sua lógica para um fluxograma simples, é algo como isso:

<!--- 
retire as barras antes do hífen para funcionar. coloquei somente porque o jekyll estava reconhecendo como fechamento do comentário.
criar o fluxo: https://mermaid-js.github.io/mermaid-live-editor
downloag svg file: https://jakearchibald.github.io/svgomg/ 
graph TD
    A[Inicia execução] \-\->|job build| B(Create local changes)
    B \-\-> M{commit/push}
    M \-\-> |sim| M
    M \-\-> |não| J
    M \-\-> |sim| C{ranking_posts alterado}
    C \-\-> |sim| E[Telegram]
    E \-\-> H[Notify telegram bot]
    C \-\-> |sim| F[Email]
    C \-\-> |não| J[finaliza]
    F \-\-> G[SendGrid Actions]
--->

 {% include image.html url="/assets/images/chart1_ghactions.svg" description="" %} 

<br>

As variáveis secrets necessárias para os dois últimos `steps` de notificação (`SendGrid Action` e `Notify telegram bot`) são basicamente, no primeiro, `SENDGRID_API_KEY`(token para consumir a API da sua conta sendgrid) e no segundo, `TELEGRAM_TO` e `TELEGRAM_TOKEN` que é o ID do chat do seu usuário com o bot e o token desse bot. Depois de tudo configurado - scripts `export_goat.sh` e `edit_ranking.sh` na pasta principal e arquivo workflow `ranking_featured.yml` dentro da pasta `.github/workflows` -, o resultado de uma execução padrão, com alteração no ranking, é visto assim, nos logs da aba Actions do repositório:

{% include image.html url="/assets/images/workflow1.png" description="" %}

<br>

E o disparo final no meu telegram:

{% include image.html url="/assets/images/telegram-notify.jpeg" description="" %}

<br>

E então, ao conferir a página inicial:

{% include image.html url="/assets/images/marllus-featured.png" description="Artigos em destaque e estrelinhas nos seus lugares" %}<br>

Desafio aceito e saga concluída. Agora os destaques serão automaticamente reorganizados no meu blog e ainda serei notificado sobre isso por e-mail e telegram! Tudo isso de graça, usando *Github Actions*, *Jekyll* e o contador "catraca" *Goatcounter*. As possibilidades são inúmeras, pois como viu, da pra pensar em fluxos bem poderosos, como exemplo os [fluxos hierárquicos](https://docs.github.com/pt/actions/reference/events-that-trigger-workflows#), onde a execução de um depende de outros terminarem, com sucesso ou falha. 

Enfim, me despeço com um velho ditado que sempre sigo: <mark>o mais importante é focar na resolução mental do problema, pois o resto é só ferramenta!</mark> Um abraço e espero que tenha iluminado um pouco seu caminho!<br>Pensou em um fluxo e não sabe se é possível? Comenta aí!<br>:)
